* [[https://leetcode-cn.com/problems/web-crawler-multithreaded][1242.
多线程网页爬虫]]
  :PROPERTIES:
  :CUSTOM_ID: 多线程网页爬虫
  :END:
[[./solution/1200-1299/1242.Web Crawler Multithreaded/README_EN.org][English
Version]]

** 题目描述
   :PROPERTIES:
   :CUSTOM_ID: 题目描述
   :END:

#+begin_html
  <!-- 这里写题目描述 -->
#+end_html

#+begin_html
  <p>
#+end_html

给你一个初始地址 startUrl 和一个 HTML
解析器接口 HtmlParser，请你实现一个 多线程的网页爬虫，用于获取与 startUrl 有 相同主机名 的所有链接。 

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

以 任意 顺序返回爬虫获取的路径。

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

爬虫应该遵循：

#+begin_html
  </p>
#+end_html

#+begin_html
  <ul>
#+end_html

#+begin_html
  <li>
#+end_html

从 startUrl 开始

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

调用 HtmlParser.getUrls(url) 从指定网页路径获得的所有路径。

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

不要抓取相同的链接两次。

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

仅浏览与 startUrl 相同主机名 的链接。

#+begin_html
  </li>
#+end_html

#+begin_html
  </ul>
#+end_html

#+begin_html
  <p>
#+end_html

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

如上图所示，主机名是 example.org 。简单起见，你可以假设所有链接都采用 http
协议，并且没有指定 端口号。举个例子，链接 http://leetcode.com/problems
和链接 http://leetcode.com/contest 属于同一个 主机名，
而 http://example.org/test 与 http://example.com/abc
并不属于同一个 主机名。

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

HtmlParser 的接口定义如下：

#+begin_html
  </p>
#+end_html

#+begin_html
  <pre>
  interface HtmlParser {
    // Return a list of all urls from a webpage of given <em>url</em>.
    // This is a blocking call, that means it will do HTTP request and return when this request is finished.
    public List&lt;String&gt; getUrls(String url);
  }</pre>
#+end_html

#+begin_html
  <p>
#+end_html

注意一点，getUrls(String url) 模拟执行一个HTTP的请求。
你可以将它当做一个阻塞式的方法，直到请求结束。 getUrls(String
url) 保证会在 15ms 内返回所有的路径。
单线程的方案会超过时间限制，你能用多线程方案做的更好吗？

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

对于问题所需的功能，下面提供了两个例子。为了方便自定义测试，你可以声明三个变量 urls，edges 和 startUrl。但要注意你只能在代码中访问 startUrl，并不能直接访问 urls 和 edges。

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

 

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

拓展问题：

#+begin_html
  </p>
#+end_html

#+begin_html
  <ol>
#+end_html

#+begin_html
  <li>
#+end_html

假设我们要要抓取 10000 个节点和 10
亿个路径。并且在每个节点部署相同的的软件。软件可以发现所有的节点。我们必须尽可能减少机器之间的通讯，并确保每个节点负载均衡。你将如何设计这个网页爬虫？

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

如果有一个节点发生故障不工作该怎么办？

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

如何确认爬虫任务已经完成？

#+begin_html
  </li>
#+end_html

#+begin_html
  </ol>
#+end_html

#+begin_html
  <p>
#+end_html

 

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

示例 1：

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

#+begin_html
  </p>
#+end_html

#+begin_html
  <pre>
  <strong>输入：
  </strong>urls = [
  &nbsp; &quot;http://news.yahoo.com&quot;,
  &nbsp; &quot;http://news.yahoo.com/news&quot;,
  &nbsp; &quot;http://news.yahoo.com/news/topics/&quot;,
  &nbsp; &quot;http://news.google.com&quot;,
  &nbsp; &quot;http://news.yahoo.com/us&quot;
  ]
  edges = [[2,0],[2,1],[3,2],[3,1],[0,4]]
  startUrl = &quot;http://news.yahoo.com/news/topics/&quot;
  <strong>输出：</strong>[
  &nbsp; &quot;http://news.yahoo.com&quot;,
  &nbsp; &quot;http://news.yahoo.com/news&quot;,
  &nbsp; &quot;http://news.yahoo.com/news/topics/&quot;,
  &nbsp; &quot;http://news.yahoo.com/us&quot;
  ]
  </pre>
#+end_html

#+begin_html
  <p>
#+end_html

示例 2：

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

#+begin_html
  </p>
#+end_html

#+begin_html
  <pre>
  <strong>输入：</strong>
  urls = [
  &nbsp; &quot;http://news.yahoo.com&quot;,
  &nbsp; &quot;http://news.yahoo.com/news&quot;,
  &nbsp; &quot;http://news.yahoo.com/news/topics/&quot;,
  &nbsp; &quot;http://news.google.com&quot;
  ]
  edges = [[0,2],[2,1],[3,2],[3,1],[3,0]]
  startUrl = &quot;http://news.google.com&quot;
  <strong>输出：</strong>[&quot;http://news.google.com&quot;]
  <strong>解释：</strong>startUrl 链接与其他页面不共享一个主机名。</pre>
#+end_html

#+begin_html
  <p>
#+end_html

 

#+begin_html
  </p>
#+end_html

#+begin_html
  <p>
#+end_html

提示：

#+begin_html
  </p>
#+end_html

#+begin_html
  <ul>
#+end_html

#+begin_html
  <li>
#+end_html

1 <= urls.length <= 1000

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

1 <= urls[i].length <= 300

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

startUrl 是 urls 中的一个。

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

主机名的长度必须为 1 到 63 个字符（包括点 . 在内），只能包含从 “a” 到
“z” 的 ASCII 字母和 “0” 到 “9” 的数字，以及中划线 “-”。

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

主机名开头和结尾不能是中划线 “-”。

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

参考资料：https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames

#+begin_html
  </li>
#+end_html

#+begin_html
  <li>
#+end_html

你可以假设路径都是不重复的。

#+begin_html
  </li>
#+end_html

#+begin_html
  </ul>
#+end_html

** 解法
   :PROPERTIES:
   :CUSTOM_ID: 解法
   :END:

#+begin_html
  <!-- 这里可写通用的实现逻辑 -->
#+end_html

#+begin_html
  <!-- tabs:start -->
#+end_html

*** *Python3*
    :PROPERTIES:
    :CUSTOM_ID: python3
    :END:

#+begin_html
  <!-- 这里可写当前语言的特殊实现逻辑 -->
#+end_html

#+begin_src python
#+end_src

*** *Java*
    :PROPERTIES:
    :CUSTOM_ID: java
    :END:

#+begin_html
  <!-- 这里可写当前语言的特殊实现逻辑 -->
#+end_html

#+begin_src java
#+end_src

*** *...*
    :PROPERTIES:
    :CUSTOM_ID: section
    :END:
#+begin_example
#+end_example

#+begin_html
  <!-- tabs:end -->
#+end_html
